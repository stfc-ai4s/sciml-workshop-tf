{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Filter maximisation\n", "\n", "In this notebook we will develop a set of functions that allow you to see what images maximise filters inside the network. Much of the notebok here is based on the [How convolutional networks see the world](https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html) blog post, but we have adapted the code to work with tensorflow, rather than straight keras.\n", "\n", "You should be able to take these sets of functions and reuse them for your own problems."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import tensorflow as tf\n", "from tqdm import notebook \n", "import numpy as np\n", "from ipywidgets import widgets\n", "import matplotlib.pyplot as plt\n", "from tensorflow import keras\n", "from tensorflow.keras.applications import VGG16\n", "from skimage.color import rgb2gray\n", "from skimage.transform import resize"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Build a model that outputs intermediate filter values\n", "\n", "To do filter maximisation we need to have models that output the values of filters in the middile of the network as information flows through. To do this we \n", "\n", "* Get the names of the intermediate convolutional layers\n", "* Build a new model where every convoutional layer is also an output layer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def make_activation_model(model):\n", "    \"\"\"Make an 'activation model' for the pre-trained model\n", "    \n", "    Takes an existing, pre-trained model and finds all convolution layers.\n", "    Then creates a new model where every convolutional layer is also an \n", "    output layer.\n", "    \n", "    Args:\n", "        model: a pre-trained model with convolutional layers\n", "    Returns:\n", "        an activation model where all convolutional layers are also output layers\n", "    \"\"\"\n", "    layers = [layer for layer in model.layers if 'conv' in layer.name]\n", "    layer_outputs = [layer.output for layer in layers]\n", "    layer_names = [layer.name for layer in layers]\n", "    \n", "    activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)\n", "    return activation_model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Find an image to maximise the filter activity\n", "\n", "* Take the gradient of the input image with respect to filter's activity \n", "* Update the input image to maximise this derivative "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def maximize_filter_activation(input_img, activation_model, layer_index, filter_index, n_iter=20, step=1):\n", "    \"\"\"Maximize the activation of a given filter\n", "    \n", "    Based on the example code for Keras by F. Chollet:\n", "    https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html\n", "    \n", "    Args:\n", "        input_img: input image to maxmize the activation for. This is usually gaussian random noise. \n", "        activation_model: an activation model to use to sample filters from\n", "        layer: layer to maximize given filter for.\n", "        layer_index: index of the layer to maximize.\n", "        \n", "    Returns:\n", "        Maximized output for the given filter of shape (num filters, h, w, channels)\n", "        loss for that filter\n", "    \"\"\"\n", "    input_img_data = tf.constant(input_img, dtype=tf.float32)\n", "    for i in range(n_iter):\n", "        with tf.GradientTape() as tape:\n", "            tape.watch(input_img_data)\n", "            loss = tf.math.reduce_mean(activation_model(input_img_data)[layer_index][:, :, :, filter_index])\n", "            # compute the gradient of the input picture wrt this loss\n", "            grads = tape.gradient(loss, input_img_data)\n", "            # normalization trick: we normalize the gradient\n", "            grads /= (tf.math.sqrt(tf.math.reduce_mean(tf.math.square(grads))) + 1e-5)\n", "            input_img_data += (grads * step)\n", "\n", "    return input_img_data, loss"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Random filter sampling\n", "\n", "Here we take the filters from the layer `layer_index` and take a random sample of the filters and maximise the imput images with respect to them."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def random_filter_samples(input_img, activation_model, layer_index, n_samples=10, **kwargs):\n", "    \"\"\"Maximize the activation for a random sample of filters\n", "    \n", "    Args:\n", "        input_img: input image to maxmize the activation for. This is usually gaussian random noise. \n", "        activation_model: an activation model to use to sample filters from\n", "        layer_index: index of the layer to maximize filters for.\n", "        \n", "    Returns:\n", "        list of maximized activations for a random sample of filters.\n", "    \"\"\"\n", "    n_filters = activation_model.output_shape[layer_index][-1]\n", "    n_samples = n_filters if n_filters < n_samples else n_samples\n", "    indices = np.random.choice(n_filters, n_samples, replace=False)\n", "    outputs = []\n", "    for filter_index in indices:\n", "        output = maximize_filter_activation(input_img, activation_model, layer_index, filter_index, **kwargs)\n", "        outputs.append(output[0].numpy())\n", "    return outputs\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Maximum filter sampling\n", "\n", "Here we take the filters from the layer `layer_index` and take the `n_samples` filters with the greatest activation values."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def max_filter_samples(input_img, activation_model, layer_index, n_samples=5, limit=32, **kwargs):\n", "    \"\"\"Get the filters that respond the most to input signals. We get this by seleting the filters with the lowest\n", "    loss as returned by maximize_filter_activation    \n", "    Args:\n", "        input_img: input image to maxmize the activation for. This is usually gaussian random noise. \n", "        activation_model: an activation model to use to sample filters from\n", "        layer_index: index of the layer to maximize filters for.\n", "        n_select: the top number of filters to return\n", "        \n", "    Returns:\n", "        list of maximized activations for a random sample of filters.\n", "    \"\"\"\n", "    n_filters = activation_model.output_shape[layer_index][-1]\n", "    indices = range(n_filters)\n", "    if len(indices) > limit:\n", "        indices = range(limit)\n", "    outputs = []\n", "    for filter_index in indices:\n", "        output = maximize_filter_activation(input_img, activation_model, layer_index, filter_index, **kwargs)\n", "        outputs.append([output[0].numpy(), output[1].numpy()])\n", "    outputs = sorted(outputs, key=lambda x: x[1], reverse=True)\n", "    outputs = [o[0] for o in outputs]\n", "    n_samples = n_filters if n_filters < n_samples else n_samples\n", "    return outputs[:n_samples]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## The master function that controls the others\n", "\n", "This is the function that you call at the top level. You need to tell it the model to feed, the input image, which layers of the network you want to look at, whether to sample randomly or maximum activation filters and how many filters to look at in each layer."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def sample_model_filters(model, input_img, layers=[], mode='random', n_samples=5, **kwargs):\n", "    \"\"\"Sample filters from a model\n", "    \n", "    This will randomly sample filters from the model and\n", "    maximise the activation of that filter using the given input image/\n", "    \n", "    Args:\n", "        model: input model to sample filters from\n", "        input_img: the input image to use to maximise filter activation.\n", "            Must match the input shape expected by the model.\n", "        layers: the index of the layers to sample\n", "    \n", "    Returns:\n", "        list of samples of maximized input for filters form each layer of the model\n", "    \"\"\"\n", "    activation_model = make_activation_model(model)\n", "    model_layer_outputs = [ ]\n", "    if layers == []:\n", "        layers = range(len(activation_model.output_shape))\n", "    for layer_index in notebook.tqdm(layers):\n", "        if mode == 'random':\n", "            output = random_filter_samples(input_img, activation_model, layer_index, n_samples,  **kwargs)\n", "        elif mode == 'max':\n", "            output = max_filter_samples(input_img, activation_model, layer_index, n_samples, **kwargs)\n", "        model_layer_outputs.append(output)\n", "    return model_layer_outputs"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Set up the network and the image\n", "\n", "* Set up a random image as input, you can choose the dimensions.\n", "* Load a pre-trained model from keras - we will use `VGG16` with the `imagenet` weights"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["img_width = 64\n", "img_height = 64\n", "model = VGG16(include_top=False, weights='imagenet')\n", "# we start from a gray image with some noise\n", "input_img = np.random.random((1, img_width, img_height, 3)) * 20 + 128."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Run the maximisation procedure\n", "\n", "In the first instance let's run the first, fifth and eigth layers and sample 3 filters from each. We can see how the filters develop through the network. We will run the image maximisation for 20 steps with a scaling of steps of 5."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_layer_outputs = sample_model_filters(model, input_img, layers=[0, 4, 7], \n", "                                           mode='random', n_samples=3, n_iter=40, step=5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Visualise the results\n", "\n", "Using `ipython_widgets` we will look at the outputs of the maximisation."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@widgets.interact(layer_outputs=widgets.fixed(model_layer_outputs), \n", "                  index=widgets.Select(options=range(len(model_layer_outputs))))\n", "def plot_filters(layer_outputs, index):\n", "    outputs = layer_outputs[index]\n", "    n_filters = len(outputs)\n", "\n", "    fig, axes = plt.subplots(n_filters, 1, figsize=(20, 18))\n", "    fig.subplots_adjust(hspace=0.1, wspace=0.1)\n", "    for ax, l in zip(axes.flatten(), outputs):\n", "        img = rgb2gray(l)\n", "        ax.imshow(np.squeeze(img), cmap='Blues', interpolation='gaussian')\n", "        ax.axis('off')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Exercises\n", "\n", "* Play around with looking at different layers.\n", "* Try feeding an actual image rather than a random array, what are the results?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def preprocess_image(image_path, size=0.3):\n", "    # Util function to open, resize and format pictures\n", "    # into appropriate arrays.\n", "    img = keras.preprocessing.image.load_img(image_path)\n", "    img = keras.preprocessing.image.img_to_array(img)\n", "    img = resize(img, (int(img.shape[0]*size), int(img.shape[1]*size)))\n", "    img = np.expand_dims(img, axis=0)\n", "\n", "    return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["base_image_path = tf.keras.utils.get_file(\"sky.jpg\", \"https://i.imgur.com/aGBdQyK.jpg\")\n", "img = preprocess_image(base_image_path)\n", "model_layer_outputs = sample_model_filters(model, img, layers=[7], mode='random', n_samples=1, n_iter=20, step=5)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["imgg = rgb2gray((model_layer_outputs[0][0]))\n", "fig, ax = plt.subplots(1, 2, figsize=(20, 20))\n", "ax[0] .imshow(np.squeeze(rgb2gray(img)), cmap='Blues')\n", "ax[1].imshow(np.squeeze(imgg), cmap='Blues')\n", "for i in range(2):\n", "    ax[i].set_xticks([])\n", "    ax[i].set_yticks([])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.6"}}, "nbformat": 4, "nbformat_minor": 4}